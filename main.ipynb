{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; line-height: 1.6; color: #E0E0E0; background-color: #2D2D2D; border: 1px solid #444; border-radius: 10px; padding: 25px; margin: 20px 0;\">\n\n <h1 style=\"color: #4CAF50; border-bottom: 2px solid #4CAF50; padding-bottom: 10px; font-weight: 500;\">\n        Part 1: An Introduction to Multi-Task Learning (MTL)\n    </h1>\n\n<p style=\"font-size: 18px; color: #C5C5C5;\">\n        Welcome to our journey into Multi-Task Learning! In this section, we'll break down the core concepts behind this powerful machine learning paradigm. We'll explore what it is, why it's so useful, and define the specific goal for our project.\n    </p>\n\n<h2 style=\"color: #00BCD4; margin-top: 30px; font-weight: 500;\">\n        üß† What is Multi-Task Learning?\n    </h2>\n\n<p style=\"font-size: 16px; color: #C5C5C5;\">\n        At its heart, <strong>Multi-Task Learning (MTL)</strong> is a simple but profound idea: instead of training one expert model for each individual task, we train a <strong>single, unified model</strong> to solve multiple related tasks simultaneously.\n    </p>\n\n<div style=\"background-color: #333333; border-left: 5px solid #00BCD4; padding: 15px; margin: 20px 0; border-radius: 5px;\">\n        <strong style=\"color: #00BCD4;\">Analogy: Learning Like a Human</strong>\n        <p style=\"margin: 5px 0 0 0; color: #C5C5C5;\">\n            Think about learning to play the piano. The skills you acquire‚Äîlike finger dexterity, reading sheet music, and understanding rhythm‚Äîdon't just disappear. They make it significantly easier to learn another instrument, like the guitar or the organ. The tasks are different, but they share a foundational structure. MTL aims to capture this shared structure computationally.\n        </p>\n    </div>\n\n<h2 style=\"color: #FFC107; margin-top: 30px; font-weight: 500;\">\n        üèÜ Why Use Multi-Task Learning? The Core Benefits\n    </h2>\n\n<p style=\"font-size: 16px; color: #C5C5C5;\">\n        MTL isn't just an academic exercise; it offers tangible advantages over the traditional \"one model per task\" approach, which we call Single-Task Learning (STL).\n    </p>\n\n<ul style=\"list-style-type: none; padding-left: 0; color: #C5C5C5;\">\n        <li style=\"background-color: #383838; margin-bottom: 10px; padding: 15px; border-radius: 8px; border-left: 5px solid #FFC107;\">\n            <strong>Improved Generalization:</strong> By forcing the model to find a representation that works for all tasks, we discourage it from overfitting to any single task. This often leads to better performance on unseen data.\n        </li>\n        <li style=\"background-color: #383838; margin-bottom: 10px; padding: 15px; border-radius: 8px; border-left: 5px solid #FFC107;\">\n            <strong>Computational Efficiency:</strong> We train, deploy, and maintain only one model instead of many. This saves training time, memory, and inference costs. One model is cheaper than N\n             models!\n        </li>\n        <li style=\"background-color: #383838; margin-bottom: 10px; padding: 15px; border-radius: 8px; border-left: 5px solid #FFC107;\">\n            <strong>Implicit Data Augmentation:</strong> A task with little data can \"borrow\" statistical strength from a related, data-rich task. The model learns a rich feature representation from the big task, which the small task can then leverage.\n        </li>\n    </ul>\n\n<h2 style=\"color: #F44336; margin-top: 30px; font-weight: 500;\">\n        üéØ Our Project Goal\n    </h2>\n\n<div style=\"background-color: #402F2F; border: 1px solid #F44336; padding: 20px; text-align: center; border-radius: 8px;\">\n        <p style=\"font-size: 18px; color: #F5C5C0; margin: 0;\">\n            Our mission is to build a Convolutional Neural Network (CNN) that analyzes an image of a celebrity's face and <strong>simultaneously predicts multiple attributes</strong>. For example, given one image, it will tell us if the person is:\n        </p>\n        <p style=\"font-size: 20px; font-weight: bold; color: #FFFFFF; margin-top: 10px;\">\n            Smiling? + Wearing Eyeglasses? + Has Blond Hair?\n        </p>\n    </div>\n    \n<p style=\"font-size: 16px; color: #C5C5C5; margin-top: 20px;\">\n        Let's get started by setting up our environment and loading the data!\n    </p>\n\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; line-height: 1.6; color: #E0E0E0; background-color: #2D2D2D; border: 1px solid #444; border-radius: 10px; padding: 25px; margin: 20px 0;\">\n\n <h1 style=\"color: #4CAF50; border-bottom: 2px solid #4CAF50; padding-bottom: 10px; font-weight: 500;\">\n        Part 2: Setting Up the Environment and Data\n    </h1>\n\n <p style=\"font-size: 18px; color: #C5C5C5;\">\n        Now for the hands-on part! Before we can build our models, we need to prepare our workspace. This involves importing the necessary libraries, loading the CelebA dataset's attribute file, and selecting the specific facial features we want our model to predict.\n    </p>\n\n<h2 style=\"color: #00BCD4; margin-top: 30px; font-weight: 500;\">\n        Step 2.1: Import Libraries\n    </h2>\n    <p style=\"font-size: 16px; color: #C5C5C5;\">\n        First, let's import all the tools we'll need. We'll use <code>pandas</code> for data manipulation, <code>torch</code> and <code>torchvision</code> for building our neural network and handling image data, and <code>matplotlib</code> for visualization.\n    </p>\n\n</div>\n","metadata":{}},{"cell_type":"code","source":"# Core libraries\nimport os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\n\n# PyTorch\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Sklearn for metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, multilabel_confusion_matrix\n\n# Set device\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {DEVICE}\")\n\n# Set a consistent style for plots\nplt.style.use('dark_background')\nsns.set_palette(\"viridis\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T12:33:46.287036Z","iopub.execute_input":"2025-09-13T12:33:46.287391Z","iopub.status.idle":"2025-09-13T12:33:57.926582Z","shell.execute_reply.started":"2025-09-13T12:33:46.287367Z","shell.execute_reply":"2025-09-13T12:33:57.925479Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"}],"execution_count":1}]}